# -*- coding: utf-8 -*-
"""
Neo4j çŸ¥è¯†å›¾è°±å¯¼å…¥ï¼ˆå…ˆæ¸…ç©ºå†ç”Ÿæˆï½œæŒ‰ä½ æœ€æ–°å…³ç³»è¡¨ï½œNeo4j 4.3 å…¼å®¹ç‰ˆï¼‰
å…³ç³»ï¼ˆæ–¹å‘å›ºå®šï¼‰ï¼š
- æ¡ˆä¾‹ â€”æ¥æºâ†’ è¯•éªŒé¡¹ç›®
- æ¡ˆä¾‹ â€”å¯¹åº”â†’ èƒ½åŠ›æŒ‡æ ‡
- æ¡ˆä¾‹ â€”å¤„äºŽâ†’ è¯•éªŒé˜¶æ®µ
- æ¡ˆä¾‹ â€”æ¶‰åŠâ†’ å²—ä½èŒè´£
- æ¡ˆä¾‹ â€”å‡ºçŽ°â†’ é—®é¢˜
- é—®é¢˜ â€”é‡‡ç”¨â†’ è§£å†³æ–¹æ³•
- è§£å†³æ–¹æ³• â€”äº§ç”Ÿâ†’ æ•´æ”¹ç»“æžœ
- æ¡ˆä¾‹ â€”å½¢æˆâ†’ åæ€

æ³¨æ„ç‚¹ï¼š
- æäº¤äº‹åŠ¡ç»Ÿä¸€ä½¿ç”¨ g.commit(tx)ï¼ˆä½ çš„ py2neo æŽ¨èç”¨æ³•ï¼Œé¿å… DeprecationWarningï¼‰ã€‚
- æŒ‡æ ‡åˆ†å±‚â€œå±žäºŽâ€å…³ç³»ç”¨ py2neo çš„ Relationshipã€‚
- æ‰€æœ‰ tx.run å†…çš„ä¸­æ–‡å…³ç³»åå·²ç”¨åå¼•å·åŒ…è£¹ï¼Œé¿å…è§£æžé—®é¢˜ã€‚
- å¢žåŠ è¡¨å¤´â€œå…œåº•æ˜ å°„â€ï¼Œè½»å¾®æ”¹åˆ—åä¹Ÿèƒ½æ­£å¸¸å¯¼å…¥ã€‚
"""

import re
import hashlib
import pandas as pd
from py2neo import Graph, Node, Relationship

# ===== 0) åŸºæœ¬é…ç½® =====
NEO4J_URI  = "bolt://localhost:7687"
NEO4J_AUTH = ("neo4j", "dsm123456")

INDICATOR_XLSX = r"C:\Users\åˆ˜èˆªåš\Desktop\è¯„ä»·æŒ‡æ ‡çš„åˆ†å¸ƒ.xlsx"
CASE_XLSX      = r"C:\Users\åˆ˜èˆªåš\Desktop\ä¸´åºŠè¯•éªŒåè°ƒè¿‡ç¨‹æ¡ˆä¾‹åº“ï¼ˆçŸ¥è¯†å›¾è°±ç‰ˆï¼‰.xlsx"

BATCH_SZ = 500

# æ¸…ç©ºä¸Žé‡å»ºå¼€å…³
CLEAR_ALL_DATA     = True   # True=å¯¼å…¥å‰æ¸…ç©ºæ‰€æœ‰èŠ‚ç‚¹ä¸Žå…³ç³»
RESET_CONSTRAINTS  = False  # True=è¿žåŒçº¦æŸä¸€èµ·é‡ç½®ï¼ˆä¸€èˆ¬ä¸éœ€è¦ï¼‰

# ===== 1) å·¥å…·å‡½æ•° =====
def sval(x):
    if pd.isna(x):
        return ""
    s = str(x).strip().replace("\u3000", " ")
    return re.sub(r"\s+", " ", s)

RE_LV1_FULL = re.compile(r"^\s*(\d+)\s*(.*)$")
RE_LV2_FULL = re.compile(r"^\s*(\d+\.\d+)\s*(.*)$")
RE_LV3_FULL = re.compile(r"^\s*(\d+\.\d+\.\d+)\s*(.*)$")
RE_CODE_ANY = re.compile(r"^\s*(\d+(?:\.\d+)*)")

def unk_code(text):
    base = text if text else "EMPTY"
    return "UNK::" + hashlib.md5(base.encode("utf-8")).hexdigest()[:10]

def case_uid(case_name):
    # å½“å‰ä»¥â€œæ¡ˆä¾‹åç§°â€æ´¾ç”Ÿ UIDï¼›è‹¥æœªæ¥è½¬å¢žé‡å¯¼å…¥ï¼Œå»ºè®®æ”¹ç”¨â€œæ¡ˆä¾‹ç¼–å·â€åˆ—ä½œä¸ºä¸»é”®æ¥æº
    return hashlib.md5(case_name.encode("utf-8")).hexdigest()[:12]

def drop_constraints(db: Graph):
    # å…¼å®¹ Neo4j 4.3 çš„æ—§è¯­æ³•
    cqls = [
        "DROP CONSTRAINT ON (i:Indicator) ASSERT i.code IS UNIQUE",
        "DROP CONSTRAINT ON (c:Case)      ASSERT c.name IS UNIQUE",
        "DROP CONSTRAINT ON (p:Problem)   ASSERT p.uid  IS UNIQUE",
        "DROP CONSTRAINT ON (a:Action)    ASSERT a.uid  IS UNIQUE",
        "DROP CONSTRAINT ON (r:Result)    ASSERT r.uid  IS UNIQUE",
        "DROP CONSTRAINT ON (f:Reflection)ASSERT f.uid  IS UNIQUE",
        "DROP CONSTRAINT ON (s:Stage)     ASSERT s.name IS UNIQUE",
        "DROP CONSTRAINT ON (ro:Role)     ASSERT ro.name IS UNIQUE",
        "DROP CONSTRAINT ON (prj:Project) ASSERT prj.name IS UNIQUE",
        "DROP CONSTRAINT ON (ctr:Center)  ASSERT ctr.name IS UNIQUE",
    ]
    for c in cqls:
        try:
            db.run(c)
        except Exception as e:
            msg = str(e).lower()
            if ("exist" in msg) or ("no such" in msg) or ("not found" in msg):
                pass
            else:
                raise

def create_constraints(db: Graph):
    # å…¼å®¹ Neo4j 4.3 æ—§è¯­æ³•
    cqls = [
        "CREATE CONSTRAINT ON (i:Indicator) ASSERT i.code IS UNIQUE",
        "CREATE CONSTRAINT ON (c:Case)      ASSERT c.name IS UNIQUE",
        "CREATE CONSTRAINT ON (p:Problem)   ASSERT p.uid  IS UNIQUE",
        "CREATE CONSTRAINT ON (a:Action)    ASSERT a.uid  IS UNIQUE",
        "CREATE CONSTRAINT ON (r:Result)    ASSERT r.uid  IS UNIQUE",
        "CREATE CONSTRAINT ON (f:Reflection)ASSERT f.uid  IS UNIQUE",
        "CREATE CONSTRAINT ON (s:Stage)     ASSERT s.name IS UNIQUE",
        "CREATE CONSTRAINT ON (ro:Role)     ASSERT ro.name IS UNIQUE",
        "CREATE CONSTRAINT ON (prj:Project) ASSERT prj.name IS UNIQUE",
        "CREATE CONSTRAINT ON (ctr:Center)  ASSERT ctr.name IS UNIQUE",
    ]
    for c in cqls:
        try:
            db.run(c)
        except Exception as e:
            msg = str(e).lower()
            if ("already" in msg) or ("equivalent schema" in msg):
                pass
            else:
                raise

def eval_one(db: Graph, q: str, title: str):
    try:
        val = db.run(q).evaluate()
        print("{}: {}".format(title, val))
    except Exception as e:
        print("{} æŸ¥è¯¢å‡ºé”™: {}".format(title, e))

# é˜¶æ®µå½’ä¸€ï¼ˆå¯é€‰ï¼‰
STAGE_MAP = {
    "å‡†å¤‡é˜¶æ®µ": "å‡†å¤‡é˜¶æ®µ",
    "è¿›è¡Œé˜¶æ®µ": "è¿›è¡Œé˜¶æ®µ",
    "ç»“é¢˜é˜¶æ®µ": "ç»“é¢˜é˜¶æ®µ",
    "éšè®¿é˜¶æ®µ": "è¿›è¡Œé˜¶æ®µ",
    "ç»“æŸé˜¶æ®µ": "ç»“é¢˜é˜¶æ®µ",
    "æ”¶å°¾é˜¶æ®µ": "ç»“é¢˜é˜¶æ®µ"
}

# ===== è¡¨å¤´â€œå…œåº•æ˜ å°„â€ =====
IND_COLS = {
    "ä¸€çº§æŒ‡æ ‡": ["ä¸€çº§æŒ‡æ ‡", "ä¸€çº§", "Level1", "L1"],
    "äºŒçº§æŒ‡æ ‡": ["äºŒçº§æŒ‡æ ‡", "äºŒçº§", "Level2", "L2"],
    "ä¸‰çº§æŒ‡æ ‡": ["ä¸‰çº§æŒ‡æ ‡", "ä¸‰çº§", "Level3", "L3"],
}
CASE_COLS = {
    "æ¡ˆä¾‹":     ["æ¡ˆä¾‹", "æ¡ˆä¾‹åç§°", "Case", "æ¡ˆä¾‹å"],
    "è¯•éªŒé¡¹ç›®": ["è¯•éªŒé¡¹ç›®", "é¡¹ç›®", "ç ”ç©¶é¡¹ç›®", "Project"],
    "èƒ½åŠ›æŒ‡æ ‡": ["èƒ½åŠ›æŒ‡æ ‡", "æŒ‡æ ‡", "Indicator"],
    "è¯•éªŒé˜¶æ®µ": ["è¯•éªŒé˜¶æ®µ", "é˜¶æ®µ", "Stage"],
    "å²—ä½èŒè´£": ["å²—ä½èŒè´£", "èŒè´£", "Role"],
    "é—®é¢˜":     ["é—®é¢˜", "é—®é¢˜æè¿°", "Problem"],
    "è§£å†³æ–¹æ³•": ["è§£å†³æ–¹æ³•", "æ•´æ”¹æŽªæ–½", "Action"],
    "æ•´æ”¹ç»“æžœ": ["æ•´æ”¹ç»“æžœ", "ç»“æžœ", "Result"],
    "åæ€":     ["åæ€", "æ¡ˆä¾‹åæ€", "Reflection"],
}

def pick_col(df: pd.DataFrame, canon_name: str, mapping: dict):
    for cand in mapping.get(canon_name, []):
        if cand in df.columns:
            return cand
    return None

# ===== 2) è¿žæŽ¥ =====
g = Graph(NEO4J_URI, auth=NEO4J_AUTH)

# ===== 3) æ¸…ç©ºï¼ˆå¯é€‰ï¼‰=====
if CLEAR_ALL_DATA:
    print("âš ï¸ æ­£åœ¨æ¸…ç©ºçŽ°æœ‰å›¾æ•°æ®ï¼ˆèŠ‚ç‚¹ä¸Žå…³ç³»ï¼‰...")
    g.run("MATCH (n) DETACH DELETE n")
    print("âœ… æ¸…ç©ºå®Œæˆã€‚")
    if RESET_CONSTRAINTS:
        print("âš ï¸ æ­£åœ¨é‡ç½®å”¯ä¸€æ€§çº¦æŸ...")
        drop_constraints(g)
        create_constraints(g)
        print("âœ… çº¦æŸå·²é‡ç½®ã€‚")
    else:
        create_constraints(g)
else:
    create_constraints(g)

# ===== 4) æŒ‡æ ‡ä½“ç³»ï¼ˆCenter/å±žäºŽ å±‚çº§ï¼‰=====
df_ind = pd.read_excel(INDICATOR_XLSX)
print("æŒ‡æ ‡è¡¨å¤´:", df_ind.columns.tolist())

col_l1 = pick_col(df_ind, "ä¸€çº§æŒ‡æ ‡", IND_COLS)
col_l2 = pick_col(df_ind, "äºŒçº§æŒ‡æ ‡", IND_COLS)
col_l3 = pick_col(df_ind, "ä¸‰çº§æŒ‡æ ‡", IND_COLS)

tx = g.begin()
center = Node("Center", name="CRCå®žè·µæ ¸å¿ƒèƒ½åŠ›è¯„ä»·æŒ‡æ ‡")
tx.merge(center, "Center", "name")

ops = 0
for _, row in df_ind.iterrows():
    # ä¸€çº§
    lvl1 = sval(row.get(col_l1)) if col_l1 else ""
    if lvl1:
        m1 = RE_LV1_FULL.match(lvl1)
        if m1:
            code1, name1 = m1.group(1), m1.group(2)
            n1 = Node("Indicator", code=code1, name=("{} {}".format(code1, name1)).strip(), level="ä¸€çº§")
            tx.merge(n1, "Indicator", "code")
            tx.merge(Relationship(n1, "å±žäºŽ", center))
    # äºŒçº§
    lvl2 = sval(row.get(col_l2)) if col_l2 else ""
    if lvl2:
        m2 = RE_LV2_FULL.match(lvl2)
        if m2:
            code2, name2 = m2.group(1), m2.group(2)
            n2 = Node("Indicator", code=code2, name=("{} {}".format(code2, name2)).strip(), level="äºŒçº§")
            tx.merge(n2, "Indicator", "code")
            p1 = Node("Indicator", code=code2.split(".")[0])
            tx.merge(p1, "Indicator", "code")
            tx.merge(Relationship(n2, "å±žäºŽ", p1))
    # ä¸‰çº§
    lvl3 = sval(row.get(col_l3)) if col_l3 else ""
    if lvl3:
        m3 = RE_LV3_FULL.match(lvl3)
        if m3:
            code3, name3 = m3.group(1), m3.group(2)
            n3 = Node("Indicator", code=code3, name=("{} {}".format(code3, name3)).strip(), level="ä¸‰çº§")
            tx.merge(n3, "Indicator", "code")
            p2_code = ".".join(code3.split(".")[:-1])
            p2 = Node("Indicator", code=p2_code)
            tx.merge(p2, "Indicator", "code")
            tx.merge(Relationship(n3, "å±žäºŽ", p2))

    ops += 1
    if ops % BATCH_SZ == 0:
        g.commit(tx)
        tx = g.begin()

g.commit(tx)
print("âœ… æŒ‡æ ‡ä½“ç³»å¯¼å…¥å®Œæˆï¼")

# ä»…æ‰¿è®¤æ­£å¼â€œä¸‰çº§â€
valid_lv3 = {}
lvl3_series = df_ind[col_l3] if col_l3 else []
for lvl3_text in lvl3_series:
    lvl3_text = sval(lvl3_text)
    m = RE_LV3_FULL.match(lvl3_text or "")
    if m:
        valid_lv3[m.group(1)] = lvl3_text

# ===== 5) æ¡ˆä¾‹åº“ï¼ˆæŒ‰æœ€æ–°å…«æ¡å…³ç³»ï¼‰=====
df_cases = pd.read_excel(CASE_XLSX)
print("æ¡ˆä¾‹è¡¨å¤´:", df_cases.columns.tolist())

c_case   = pick_col(df_cases, "æ¡ˆä¾‹", CASE_COLS)
c_proj   = pick_col(df_cases, "è¯•éªŒé¡¹ç›®", CASE_COLS)
c_ind    = pick_col(df_cases, "èƒ½åŠ›æŒ‡æ ‡", CASE_COLS)
c_stage  = pick_col(df_cases, "è¯•éªŒé˜¶æ®µ", CASE_COLS)
c_role   = pick_col(df_cases, "å²—ä½èŒè´£", CASE_COLS)
c_prob   = pick_col(df_cases, "é—®é¢˜", CASE_COLS)
c_act    = pick_col(df_cases, "è§£å†³æ–¹æ³•", CASE_COLS)
c_res    = pick_col(df_cases, "æ•´æ”¹ç»“æžœ", CASE_COLS)
c_ref    = pick_col(df_cases, "åæ€", CASE_COLS)

tx = g.begin()
ops = 0
for _, row in df_cases.iterrows():
    case_name = sval(row.get(c_case)) if c_case else ""
    if not case_name:
        print("âš ï¸ è·³è¿‡ç©ºæ¡ˆä¾‹åç§°")
        continue

    # æ¡ˆä¾‹èŠ‚ç‚¹
    tx.merge(Node("Case", name=case_name), "Case", "name")

    # è¯•éªŒé¡¹ç›®ï¼šæ¡ˆä¾‹-æ¥æº->é¡¹ç›®
    project = sval(row.get(c_proj)) if c_proj else ""
    if project:
        tx.run("""
            MERGE (c:Case {name:$c})
            MERGE (p:Project {name:$p})
            MERGE (c)-[:`æ¥æº`]->(p)
        """, c=case_name, p=project)

    # èƒ½åŠ›æŒ‡æ ‡ï¼šæ¡ˆä¾‹-å¯¹åº”->æŒ‡æ ‡ï¼ˆä»…ä¸‰çº§ä¸ºâ€œæ­£å¼â€ï¼‰
    raw_ind = sval(row.get(c_ind)) if c_ind else ""
    m = RE_CODE_ANY.match(raw_ind)
    if m and (m.group(1) in valid_lv3):
        code = m.group(1)
        formal = valid_lv3[code]
        tx.run("""
            MERGE (c:Case {name:$c})
            MERGE (i:Indicator {code:$code})
              ON CREATE SET i.name=$name, i.level='ä¸‰çº§'
            MERGE (c)-[:`å¯¹åº”`]->(i)
        """, c=case_name, code=code, name=formal)
    else:
        tx.run("""
            MERGE (c:Case {name:$c})
            MERGE (i:Indicator {code:$code})
              ON CREATE SET i.name=$name, i.level='å¾…æ ¡éªŒ', i.display=$disp
            MERGE (c)-[:`å¯¹åº”`]->(i)
        """, c=case_name, code=unk_code(raw_ind), name=raw_ind, disp=raw_ind)

    # è¯•éªŒé˜¶æ®µï¼šæ¡ˆä¾‹-å¤„äºŽ->é˜¶æ®µï¼ˆå½’ä¸€ï¼‰
    stage_raw = sval(row.get(c_stage)) if c_stage else ""
    stage = STAGE_MAP.get(stage_raw, stage_raw)
    if stage:
        tx.run("""
            MERGE (c:Case {name:$c})
            MERGE (s:Stage {name:$s})
            MERGE (c)-[:`å¤„äºŽ`]->(s)
        """, c=case_name, s=stage)

    # å²—ä½èŒè´£ï¼šæ¡ˆä¾‹-æ¶‰åŠ->å²—ä½
    role = sval(row.get(c_role)) if c_role else ""
    if role:
        tx.run("""
            MERGE (c:Case {name:$c})
            MERGE (ro:Role {name:$r})
            MERGE (c)-[:`æ¶‰åŠ`]->(ro)
        """, c=case_name, r=role)

    # å››æ®µé“¾æ¡ï¼šå‡ºçŽ°â†’é‡‡ç”¨â†’äº§ç”Ÿï¼›ä»¥åŠå½¢æˆâ†’åæ€
    prob = sval(row.get(c_prob)) if c_prob else ""
    act  = sval(row.get(c_act))  if c_act  else ""
    res  = sval(row.get(c_res))  if c_res  else ""
    ref  = sval(row.get(c_ref))  if c_ref  else ""

    cid = case_uid(case_name)
    puid = "{}::P".format(cid)
    auid = "{}::A".format(cid)
    ruid = "{}::R".format(cid)
    fuid = "{}::F".format(cid)

    if prob:
        tx.run("""
            MERGE (p:Problem {uid:$uid})
              ON CREATE SET p.desc=$d
            MERGE (c:Case {name:$c})
            MERGE (c)-[:`å‡ºçŽ°`]->(p)
        """, uid=puid, d=prob, c=case_name)

    if prob and act:
        tx.run("""
            MERGE (p:Problem {uid:$p})
            MERGE (a:Action  {uid:$a})
              ON CREATE SET a.desc=$ad
            MERGE (p)-[:`é‡‡ç”¨`]->(a)
        """, p=puid, a=auid, ad=act)

    if act and res:
        tx.run("""
            MERGE (a:Action {uid:$a})
            MERGE (r:Result {uid:$r})
              ON CREATE SET r.desc=$rd
            MERGE (a)-[:`äº§ç”Ÿ`]->(r)
        """, a=auid, r=ruid, rd=res)

    if ref:
        tx.run("""
            MERGE (f:Reflection {uid:$f})
              ON CREATE SET f.desc=$fd
            MERGE (c:Case {name:$c})
            MERGE (c)-[:`å½¢æˆ`]->(f)
        """, f=fuid, fd=ref, c=case_name)

    ops += 1
    if ops % BATCH_SZ == 0:
        g.commit(tx)
        tx = g.begin()

g.commit(tx)
print("âœ… æ¡ˆä¾‹åº“å¯¼å…¥å®Œæˆï¼")

# ===== 6) ä½“æ£€ï¼ˆDISTINCT å£å¾„ï¼‰=====
print("\nðŸ“Š ä½“æ£€æ±‡æ€»ï¼ˆDISTINCTï¼‰")
eval_one(g, "MATCH (n) RETURN count(n)", "èŠ‚ç‚¹æ€»æ•°")
eval_one(g, "MATCH ()-[r]->() RETURN count(r)", "å…³ç³»æ€»æ•°")
eval_one(g, "MATCH (c:Case)-[:`å¯¹åº”`]->(:Indicator) RETURN count(DISTINCT c)", "å·²æŒ‚æŒ‡æ ‡çš„æ¡ˆä¾‹æ•°")
eval_one(g, "MATCH (i:Indicator {level:'å¾…æ ¡éªŒ'}) RETURN count(i)", "å¾…æ ¡éªŒæŒ‡æ ‡æ•°é‡")
eval_one(g, "MATCH (c:Case) WHERE NOT (c)-[:`å¯¹åº”`]->(:Indicator) RETURN count(c)", "æœªæŒ‚æŒ‡æ ‡æ¡ˆä¾‹")
eval_one(g, "MATCH (c:Case) WHERE NOT (c)-[:`å¤„äºŽ`]->(:Stage) RETURN count(c)", "æœªæŒ‚é˜¶æ®µæ¡ˆä¾‹")

print("\nâœ… å®Œæˆã€‚å¯åœ¨ Neo4j Browser æ£€æŸ¥ï¼š")
print("  MATCH (c:Case)-[:`å¯¹åº”`]->(i:Indicator) RETURN c,i LIMIT 20;")
print("  MATCH (c:Case)-[:`å‡ºçŽ°`]->(p:Problem)-[:`é‡‡ç”¨`]->(a:Action)-[:`äº§ç”Ÿ`]->(r:Result) RETURN c,p,a,r LIMIT 10;")
print("  MATCH (c:Case)-[:`å½¢æˆ`]->(f:Reflection) RETURN c,f LIMIT 10;")

# å¯é€‰ï¼šä¸€çœ¼æŸ¥ç©ºæŒ‚å…³é”®å…³ç³»ï¼ˆè‹¥è¦æ±‚æ¡ˆä¾‹å¿…é¡»æœ‰ æŒ‡æ ‡/é˜¶æ®µ/é¡¹ç›®ï¼‰
print("\nðŸ”Ž å…³é”®å…³ç³»æŒ‚è½½è‡ªæ£€ï¼ˆå‰ 50 æ¡ï¼‰ï¼š")
q_check = """
MATCH (c:Case)
RETURN
  c.name AS case_name,
  EXISTS((c)-[:`å¯¹åº”`]->(:Indicator)) AS hasIndicator,
  EXISTS((c)-[:`å¤„äºŽ`]->(:Stage))     AS hasStage,
  EXISTS((c)-[:`æ¥æº`]->(:Project))   AS hasProject
ORDER BY hasIndicator, hasStage, hasProject
LIMIT 50
"""
try:
    data = g.run(q_check).data()
    for row in data:
        print(row)
except Exception as e:
    print("è‡ªæ£€æŸ¥è¯¢å¤±è´¥ï¼š{}".format(e))
